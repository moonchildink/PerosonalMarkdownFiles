---
2024/1/16 moonchild
---



# 计算机体系结构笔记

1. 参考资料：
   1. [上交课件](https://www.cs.sjtu.edu.cn/~lichao/cn/slides-cn.html)
   2. [UCB:Tomasolu](https://people.eecs.berkeley.edu/~pattrsn/252F96/Lecture04.pdf)
   3. [浙大](https://qsctech.github.io/zju-icicles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/)

[TOC]





## 性能评测

### 处理器性能的衡量

执行指令的快慢
$$
= \frac{Time}{Program} \\
= \frac{Instructin}{Program} \times \frac{Cycles}{Instruction}\times \frac{Time}{Cycle} \\
= code size \times CPI \times cycle time
$$
instructions/programs : 程序运行的指令数

cycles / instruction ： 执行处理所需要的时钟周期数

time / cycle ： 每周期的时间
$$
MIPS = IPC(instruction\ per\ cycle) \times Clock\ rate
$$


### 处理器性能的比较

1. 基准测试，System Performance Evaluation Cooperative

   1. 选择公认的程序来评测性能
   2. 选择参照机器最为比较对象
   3. 不同领域有不同的基准测试

2. 性能的比较：使用几何平均值
   $$
   \sqrt[n]{\prod_{i=1}^{n}\ ratio_i}
   $$
   
3. ==Amdahl定律==

   1. 加速比：
      $$
      old\ time / new\ time
      $$

   2. 将系统中占比f的部分加速$s$倍
      $$
      new\ time  = (1-f) \times old\ time + (f/s) \times old\ time
      $$

   3. 含义：描述了对系统中某一功能提升后整体的加速比率，对于处理器的改进有重要意义。

## 指令集架构

1. 冯诺依曼模型

   1. 程序计数器
   2. 假设：指令处理是原子性的；指令X在X+1之前执行完毕。**不符合现代处理器**

2. 指令格式：以RISC-V为例

   1. 固定长度（代码密度低） 与 可变长度（代码密度高，译码逻辑复杂）

   2. 指令类型

      1. R type：寄存器形式

      2. I type：带有里技术操作

      3. S type：Store数据到内存

      4. SB type：conditional branch

      5. UJ：Unconditional Jump

      6. U type：Upper Immediate format

         ![rescv-isa](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161520455.png)

3. 操作数模型

   1. Memory-Only
   2. Accumulator
   3. Stack
   4. Load and Store

   **RISC-V采用了Load-Store模型，设置了32个整形寄存器和32个浮点寄存器。**

   ![riscv-registers](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161521621.png)

4. 寻址模式：只实现了**位移量寻址**，相对某个基址进行相对寻址

5. 数据类型：RISC-V支持针对基础类型的访存操作，整形支持32位读写，设置了基于字节或者Half word（64）的Load/Store操作

### RISC-V指令处理过程

五级流水线：IF，ID，EX，MEM，WB

数据通路与控制逻辑图要会画：

![image-20240117191608274](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171916331.png)

Control Signal：Branch, MemRead, MemToReg,ALUOp,ALUSrc, MemWrite, RegWrite

### 数据通路

1. 写出微指令
2. 根据微指令绘出数据通路

### 通路分析

根据假设：

1. Mem：200ps
2. ALU：100ps
3. Regs：50ps
4. 组合逻辑：0ps

![image-20240117191912201](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171919253.png)



## 流水线

### 流水线性能

往年李建华考了，不知道今年李志鹏会不会考。PPT和作业没涉及到相关的内容。

1. 最大吞吐率
   $$
   T_{pmax} = \frac{1}{\Delta t}
   $$

2. 实际吞吐率
   $$
   T_p = \frac{n}{m \Delta t +(n-1) \Delta t} = \frac{1}{\Delta [1+(m-1) / n]} = \frac{T_{pmax}}{1+(m-1)/ n}
   $$

3. 加速比
   $$
   S_p = \frac{nm\Delta t}{m\Delta t+(n-1)\Delta t} = \frac{nm}{m+n-1} = \frac{m}{1+(m-1)/n}
   $$

4. 效率
   $$
   E = \frac{mn\Delta t}{m(m+n-1)\Delta t} = \frac{n}{m+n-1} = \frac{S_p}{m} = T_p \Delta t
   $$

### 影响流水线性能的因素

1. 机器周期的设置：流水线性能的提高与流水线的深度成比例
2. 资源冲突
3. 数据相关和控制相关
4. 硬件流水线单元设计
5. 流水线停顿和延迟
6. 分支预测

## 相关以及分析

1. 分类

   1. 数据相关

      1. RAW：真相关
      2. WAW：输出相关/名称依赖
      3. WAR：读后写/反相关/名称依赖

      名称依赖出现的原因，是体系结构中硬件寄存器数量不足。相关于同一个寄存器名，而不是一个数值。

   2. 控制相关/控制依赖

2. 解决办法

   1. 真相关：数据前推、stall、软件层面消除真相关（compiler）、预测数值，推断执行和验证
   2. 伪相关：寄存器重命名，tomasulo，scoreboard

3. 真相关的条件：$I_B$读取了$I_A$的目的寄存器，并且：
   $$
   dist(I_A,I_B) \le dist(ID,WB) = 3
   $$

4. 真相关的解决

   1. Stall，暂停
   2. 数据前推



## 指令级并行ILP

1. 指令并行的概念：利用流水线使指令之间重叠并行处理，以提高性能。这种指令之间潜在的并行性，成为指令级并行（Instruction-Level Paralleism)。

2. ILP要求正确的执行程序，必须要保持：**数据流**和**异常行为**。

   1. 数据流：数据从生产者指令到消费者指令的实际流动；
   2. 异常行为：指令执行舜初的改变不能导致程序中发生新的异常；

   实际上，**保持程序的数据相关和控制相关**就可以保证程序的数据流和异常行为。

### 指令静态调度：循环展开

将循环展开之后，可以使用**寄存器重命名**和**指令调度**来开发更多的ILP。

核心思想是将几个循环迭代展开执行，将相关的指令拉开距离来避免空等。



### 动态调度

动态调度的核心含义是：如果第$i$条指令发生了阻塞，对于$i+1$以及之后的指令，如果与指令i无关，不应发生阻塞。也就是乱序执行。

乱序执行将ID阶段分为了两部分：

1. Issue：decode instructions，check for structural hazerds
2. Read Operands：wait until no data hazerds,then read operands

乱序执行会导致反相关（WAR和WAW）也会影响数据流。要求乱序执行必须保持：

1. 精确异常：如果发生异常时，处理器的现场与严格按程序顺序执行指令i发生异常时的现场相同——

**记分牌算法**

![image-20240116152319467](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161523512.png)

记分牌技术连接了寄存器与功能部件，对所有部件进行监听。

![img](https://pic3.zhimg.com/80/v2-fcc612c5509a6738931ba5b556d3e0d2_720w.webp)

1. 工作流程

   1. 发射：issue,decode instructions and check for structural hazards(ID1)
      1. instructions issued in program order
      2. don't issue if structural hazard
      3. don't issue if instruction is **output dependent** on any previously issued but uncompleted instructions.(**NO WAW HAZARDS**)
   2. read operand,wait until no data hazards,then read operands(ID2)
      1. All **REAL DEPENDENCIES** resolved in this stage,since we wait for instructions to write data
      2. **no forwarding of data in this mode.**
   3. 执行：execution(EX)
      1. the functional unit begins execution upon receiving operands.When the result is ready,it notifies the scoreboard that it has completed execution.
   4. 写回：write back,finish execution(WB)
      1. Stall unti no **WAR** hazards with previous instructions

2. 组成

   1. Instruction status

      1. which of 4 steps the instruciton is in.

   2. functional unit status

      1. busy: whether the unit is busy or not.
      2. Op：当前功能单元执行的操作
      3. Fi：目标寄存器
      4. Fj，Fk：源寄存器
      5. Qj，Qk：function units producing source registers Fj,Fk. 源寄存器数据的来源，功能单元
      6. Rj，Rk：Flags indicating when Fj,Fk are ready and not yet read.Set to No after operands are read. Set to no after operands are read. 表示源寄存器数据是否被占用，如果当前操作写回的寄存器正在被其他操作单元读取，那么需要等待读取结束以后再进行写回。例如指令`LD F6 34+ R2`,在指令的Issue和Read Operands阶段会被标记为Yes，当Ex阶段已经读取R2寄存器以后会标记为NO. 

   3. register result status: indicates which functional unit will write each register,if one exits. Blank when no pending instructions will write that register.

      ![image-20240116153253820](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161532859.png)

![image-20240116153510321](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161535369.png)

| 指令状态           | 执行条件                                                     | 任务                                                         |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Issue              | not busy [FU] and not Result[D]：功能部件空闲，目标寄存器已经写结果 | 标记功能部件忙碌；填入占用FU指令；分别填入目的寄存器、源寄存器；添入源寄存器来源、谁占用了源寄存器（Qj & Qk）；判断源寄存器是否可用 |
| Read Operands      | Rj and Rk                                                    | 设置Rj以及Rk为No，Qj以及Qk设置为0                            |
| Execution complete | 功能单元执行结束                                             | **读取寄存器在Execution的第一个cycle结束，可以观察Cycle 9和Cycle 10** Multi1 Rj和Rk的状态。标记当前当前指令执行结束以后的时间。 |
| Write Result       | 写回寄存器，需要注意：避免WAR Hazard，也就是：任意功能单元如果占用（还未读取结束）源寄存器为当前指令的目的寄存器，那么暂停写回。其实就是避免**WAR**冲突。 | 标记当前功能单元闲置；写回目标寄存器；任意功能单元，如果该功能单元Qj = FU，将该寄存器转让到指定功能单元。 |

![image-20240116163915203](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161639269.png)

从Cycle 9到Cycle 10可以观察到，从寄存器中取数操作只需要一个Cycle，执行过程的第一个回合结束以后就可以释放相应寄存器。

![image-20240116164209509](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401161642551.png)

如上图，Add单元已经完成了Ex阶段，希望写回寄存器，但是Divide还没从F6中读取数据，那么需要等待Divide单元执行的第一个Cycle结束，而Divide正在等待Mult写回F0寄存器。



**Tomasulo算法**

1. 采用了许多Score Boarding中的概念，但是存在两个比较大的差异：

   1. **冲突检测和执行控制是分布式的，利用保留站——控制以及缓冲器——实现**
   2. 不检查WAR和WAW相关，通过算法本身消除了

   指令中的寄存器被动态的换成数值或者是只想保留站的指针，这一过程被称为**寄存器重命名**——可以消除WAW和WAR冒险，计算结果从RS通过公共数据总线概念直通FU（function unit），无需通过寄存器。

2.  基本结构：虚拟化功能部件，使用缓冲元件实现

   1. 指令队列

   2. 加法部件 * 3：3个保留站 + 加法器

   3. 乘法部件 * 2 ：两个保留站 + 乘法器

   4.  浮点寄存器 * 4

   5. Load部件 * 5

   6. Store部件 * 3

      ![img](https://pic2.zhimg.com/80/v2-7c9ec91e4b9d9a052d39fcde3a2316c1_720w.webp)

3. 执行过程

   1. Issue: **Get instruction from FP Op Queue**,if **reservation station free** (no structural hazard), the scoreboard issues instruction and sends operands(rename registers)
   2. Execution: **Operate on operands(EX)**,when both operands ready the execute;if not ready,watch CDB for result.
   3. Write result: **Finish Execution(WB)**, wrirte on Common Data Bus to all awaiting units;mark reservation station available.

   Common Data Bus: data+==source==, like "Come From" Bus

4. 状态表

   1. Busy：Indicates reservation station is busy，表示保留站是否忙
   2. Op：operation to perform in the unit，当前单元执行的指令类型
   3. Vj,Vk: value of source operands，源操作数数值
   4. Qj,Qk: Reservation stations producing source registers，生成源寄存器的保留站。if Qj or Qk == 0 : operand ready.
   5. A: Address for Load or Store.

5. Example：可以参考[Tomasulo Example](https://people.eecs.berkeley.edu/~pattrsn/252F96/Lecture04.pdf)

6. 缺点

   1. 功能实现复杂，控制复杂：需要复杂的硬件实现相应的功能
   2. 需要大量的高速相联存储，存储开销大
   3. 非精确异常
   4. CDB是制约性能增长的瓶颈




### 动态分支预测技术

1. 在程序运行时，根据分支指令过去的历史来预测将来的行为，如果分支行为发生了变化，预测结果也跟着变化。

2. 分支预测带来的性能提升取决于：

   1. 预测的准确性

   2. 预测正确以及不正确时的开销

3. 分支历史表

   1. Branch History Table：最简单的动态分支预测方法，记录分支指令最近一次或者几次的执行情况，并且根据此来预测。Naive Method：只有一位预测位的分支预测缓冲。简单但是预测准确率不高
   2. 2bits 分支历史表：使用更多bit来记录历史，提高精度。（可以理解为记录成功的次数）

4. 分支目标缓冲区

   1. 目标：将分支成功的开销降低为0

   2. 方法：利用分支目标缓冲区

      1. 将**分支成功的分支指令的地址**和**它的分支目标地址**都放在一个缓冲区保存起来，缓冲区以**分支指令的地址**作为标识——分支目标缓冲区(branch-target buffer).

         ![image-20240117220813945](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401172208984.png)

      2. 基于BTB的流水线

         ![image-20240117220913789](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401172209831.png)

### 前瞻执行

1. 基本思想

   1. 对分支指令的结果进行猜测，并且假设这个猜测总是对的，然后按照这个猜测结果继续取值，流出和执行后续指令。——猜测执行的结果，==放到重排序缓冲区（Re-Order Bufer)==的缓冲其中；等到指令得到确认才确认写入到寄存器或者是memory之中。

   2. 基于硬件的前瞻执行结合了三种思想

      1. 动态分支预测
      2. 在控制相关的结果尚未出来之前，前瞻的执行后续指令
      3. 对各个基本块的组合进行**动态调度**

      对Tomasulo算法进行扩种，就可以支持前瞻执行。

      ==允许指令乱序执行，但是必须顺序确认==

   3. 处理结构

      ![image-20240117221507139](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401172215190.png)

   4. ROB单位项的构成

      1. 指令类型：标记是Branch,Store(Dest Address: Memory Address), Register type(Destination: Register)
      2. 目的地址：目的寄存器编号或者存储器地址
      3. 数据值字段：保存前瞻执行的结果
      4. 就绪字段：指令是否执行完成并且是否数据就绪

      ![image-20240117223613359](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401172236414.png)

   5. 在前瞻执行中，ROB是指令的操作数来源，类似Tomasulo算法中的保留站。有ROB来完成**换名**操作

   6. 执行执行步骤

      1. Issue：从指令头部取指令；如果有**空闲保留站**并**空闲ROB项**，流出指令，并放入保留站和ROB项
      2. Execution：两个操作数都就绪后可以执行；否则监听CDB
      3. 确认/commit
         1. 除了store和分支指令之外的指令：当指令到达队列头部并且结果就绪时，写入目标寄存器，并且删除指令；
         2. Store指令：写入存储器；
         3. 分支指令：预测正确的分支指令到达队列头部时，指令执行完毕。

   7. 总结

      1. 缺点：复杂的控制导致硬件复杂
      2. 优点：
         1. 通过ROB实现了顺序完成
         2. 实现==精确异常==
         3. 容易推广到整数单元上





## 存储器体系结构

### 高速缓存

参考PDF：[Cache](https://course.ece.cmu.edu/~ece447/s15/lib/exe/fetch.php%3Fmedia%3Donur-447-spring15-lecture18-caches-afterlecture.pdf)

1. 地址映射：内存在逻辑上被划分为固定大小的块（blocks），根据tag来确定对应的组，使用index bits来确定目标Block。每个Block中有8 Byte，tag+index共计5 bit，说明一共有32 Block。2 bit tag，那么有4个组，index 3 bit，每组8个Block，每个Block 8 Byte。

   ![image-20240117103041977](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171030061.png)

2. 直接相联映射：具有相同index bits的地址会映射到相同的缓存块，因此会产生地址冲突。当循环访问超过一个block——而且这两个Block具有相同的index，就会导致缓存的命中率为0。将这种效应设为“**乒乓效应**”

   ![image-20240117103155602](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171031632.png)

3. 组相联映射

   为了提升缓存的命中率，减少冲突缺失——为什么提升相联度可以降低冲突缺失？

   1. 二路组相联映射：3bit tag，2 bit index. 相比直接相联映射，冲突概率更小，但是更复杂，访问速度变慢。

      ![image-20240117104437743](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171044786.png)

   2. 四路组相联映射。发生冲突的概率进一步降低，更多的tag比较器，更宽的数据mux，更大的tag存储。

4. 全相联映射

   ![image-20240117104804826](https://raw.githubusercontent.com/moonchildink/image/main/imgs202401171048866.png)

5. 相联度

   1. 高相联度可以提升缓存命中率，降低缓存访问速度，提升硬件开销。
   2. 但是提高缓存命中率存在收益衰减趋势。

6. 置换策略：LRU，not MRU，FIFO，Random。但是当程序的Working Set大于相联度的时候，**随机策略可能更好**，可以避免抖动。



### 缓存性能优化

#### 缓存失效的情况

1. 强制性失效（第一次访问，数据还没加载到Cache）：增加块大小，预取
2. 容量失效：增加容量
3. 冲突失效（表现为缺失率较高）：增加相联度，Victim Cache，pseudo-associativity

#### 优化方法

1. 减少缺失率
   1. 更高的相联度
   2. 其他提升相联度的方法：Victim Caches, pseudo-associativity, skewed associativity.
   3. 更好的插入/替换策略
   4. 基于软件的优化方法：重构数据访问特征、重构数据在存储中的布局。如矩阵的列式存储与行式存储；将循环操作的矩阵划分为子块，让缓存可以容纳chunk以及操作的数据，本质上来说是划分了工作集，以便缓存可以容纳子工作集；
2. 减少缺失的开销/延迟
   1. 多级缓存
   2. 请求字优先
   3. 子块划分
   4. 更好的插入/替换策略
   5. 非阻塞缓存
3. Vitim Caches
   1. 在一级缓存之后添加一个Vitim Cache，将L1所移出的Cache Line放置到Vitim Cache等待再次访问。利用了程序的时间局部性的特征。如果Vitim Cache已满将数据移动到下一级Cache。
4. Pseudo-associativity
   1. 基于直接映射，但是将Cache分为两个区，逻辑上两个区相联。对于任意一次访问，首先从第一区查找，找到直接传送数据给CPU，其访问过程与直接映像Cache相同，否则查找另一个区域的相应位置，找到即发生了伪命中，否则访问下一级缓存。 
   2. 直接命中可以成为快速命中，否则经过查找为慢速命中。
   3. 取直接影响与组相联映射两者的优点。
   4. 需要保证大多数命中都是快速命中，将伪命中的数据保存到快速命中区域。
5. Skewed Associative Caches：使用不同的索引函数来访问Cache Line（way），相同的index位会映射到不同的set。**对索引进行哈希**，使其分布更加离散和随机，但是计算哈希函数提升了额外的延迟以及硬件投入。



### 缓存缺失和开销分析

1. 











## 课堂测试

1. 阐述2位分支历史信息的BHT方法的主要原理

   2位分支历史表使用2bit来记录分支跳转历史，记录分支跳转成功次数，能够更加充分地记录过去的跳转情况，主要包含4总种状态：Strongly/Weakly Taken/Not Taken. 执行到分支指令时，会查询BHT，根据历史信息得到预测的状态，如果结果是Taken，就执行跳转，令PC等于目标指令；否则令PC+=4，顺序执行。

2. 动态调度算法

   1. 阐述Tomasulo算法与推测执行中保留站的主要功能：保存待执行指令，通过这种虚拟性方法拓展功能单元；具备寄存器换名功能。
   2. Tomasulo算法能否做到精确执行：不能，因为Tomasulo算法中指令未按顺序确认
   3. 推测执行中ROB中的作用是什么：寄存器重命名；保存未执行指令；保证指令按顺序确认。

3. 数据相关检测

   1. 描述五级流水线的相关检测机制

      主要检测真相关、反相关、输出相关。

      真相关检测方法：
      $$
      dist(I_A,I_B) \le dist(ID,WB) = 3 \and Src(I_B) = Src(I_A)
      $$
      反相关检测方法：后序指令写入了一个前序指令的源寄存器

      输出相关：后序指令写了一个前序指令的目的寄存器

4. 流水线性能：
   1. 阐述影响MIPS流水线性能的原因：数据相关、分支预测失败造成的阻塞、分支指令的阻塞、反相关、输出相关
5. 流水线深度
   1. 为什么不采用100万级流水线：流水线深度越深，相关的检测逻辑就越复杂、分支预测失败造成的损失就越高，各个段寄存器越复杂，设计难度高。造成可能达不到理想的效果。
   2. 1，10，50阶流水线那种吞吐率最好：50阶；
   3. 对于单个操作来说 ，哪种延迟最低：1阶
6. 指令集设计
   1. 指令编码格式：可变长度、不可变长度
7. 摩尔定律：集成电路中晶体管的数量每隔18个月左右就要翻一番
8. Amdahl定律
9. 哈佛结构与普林斯顿结构的优缺点

   1. 哈佛结构：
      1. 优点：
         1. 并行性：指令存储与数据存储是分开的，可以在同一时刻进行指令读取和数据读取，提高了并行性；
         2. 安全性：由于指令和数据存储分离，程序无法直接修改指令存储区域，更加安全
         3. 高级存储器访问：数据和指令在各自存储器总线上传输，减少了总线竞争，提高了存储器访问效率

      2. 缺点：
         1. 复杂性与成本
         2. 灵活性受限：无法在程序运行时修改代码

   2. 普林斯顿结构
      1. 优点：
         1. 简单，灵活

      2. 缺点
         1. 并行性受限
         2. 安全性受限


​      
